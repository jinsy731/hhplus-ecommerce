# 인기상품 조회 성능 개선 보고서

---

## 1. 배경

이 기능은 특정 기간 동안의 상품 판매량을 집계하여 상위 N개의 상품을 조회하는 복잡한 통계성 쿼리를 포함하고 있으며,  
실시간 트래픽 처리에 어려움이 예상됨에 따라 **성능 병목 지점을 식별하고, 개선하기 위한 실험 및 최적화 작업**을 수행하였습니다.

---

## 2. 문제 정의

- 기존 인기 상품 조회 쿼리는 `GROUP BY`, `SUM`, `ORDER BY`, `LIMIT` 등의 연산이 복합적으로 포함되어 있어,
  대량 데이터에서 **filesort** 및 **임시 테이블 생성**이 발생함
- 3일간 판매 로그가 약 **30만 row**에 달하며, 매 호출 시마다 집계 및 정렬 작업이 발생
- SLA를 충족하지 못하는 구간 발생, 특히 **병목에 의한 커넥션 풀 고갈 및 DB CPU 부하 증가**가 문제로 드러남

---

## 3. 대상 선정

### 테스트 대상 API
- `/products/popular` (인기 상품 조회)
- 기능: 최근 3일간의 판매량을 집계하여 인기 상품 TOP N 반환
- 사용 테이블:
    - `product_sales_log`
    - `p_sales_agg_day` (일간 집계)
    - `popular_products_daily` (최종 조회용 캐시 테이블)

---

## 4. 측정 방식 (방법론)

- 테스트 도구: **k6**
- 요청 시나리오:
    - 인기 상품 API 반복 호출
    - VU 5 → 500 까지 점진 증가
- 주요 지표:
    - `http_req_duration` (전체 응답 시간)
    - `popular_product_trend` (인기 상품 요청 전용 trend)
    - `http_req_failed`, `api_call_errors`, `checks`
- 응답시간, 오류율, p95 / p99 지표 기반 비교
- 주요 DB 쿼리에 대해 `EXPLAIN`, `EXPLAIN ANALYZE`, `슬로우쿼리 로그` 분석

### 설정
- VU: 최대 500 (10만 사용자 기준, 피크 트래픽의 5%)
- 테스트 시간: 총 2분 (Ramp-up 30초, 유지 1분, Ramp-down 30초)
- 임계값:
    - `p(95) < 300ms` (SLO)
    - 실패율 5% 미만

---

## 5. 테스트 데이터 선정

### 선정 기준
- 판매 로그가 일정 이상 존재해야 신뢰도 있는 결과 도출 가능
- 실제 서비스와 유사한 scale (약 10만 개 상품 × 3일치 집계)

### 데이터 생성 방식
- 3일 간의 랜덤 판매량 (1000~5000)
- 총 30만 row 생성 (`p_sales_agg_day` 기준)

```sql
WITH RECURSIVE product_cte AS (
  SELECT 1 AS id
  UNION ALL
  SELECT id + 1 FROM product_cte WHERE id < 99999
)
INSERT INTO p_sales_agg_day (product_id, sales_day, sales_count)
SELECT id, CURDATE() - INTERVAL 2 DAY, FLOOR(1000 + RAND() * 4000)
FROM product_cte;
```

---

## 6. 비교 및 고찰

###  초기 쿼리 구조 성능 (1차 ~ 2차)
| 지표       | 수치             |
| -------- | -------------- |
| `p(95)`  | **15초 이상**     |
| 실패율      | 8.3%           |
| 커넥션 풀 고갈 | 발생 (최대 10개 제한) ||

→ 원인: 정렬 비용 + 그룹핑 병목 + 풀 부족

---

###  커넥션 풀 조정 (3~5차)
- 풀 사이즈 증가: 10 → 20 → 16
- `maxPoolSize = 코어 수 * 2~4` 공식 적용
- **큰 변화 없음**. 풀 크기 증가는 일정 수준 이상에서 **역효과 (CPU 사용량 증가)** 유발

---

###  인덱스 튜닝 (9차 ~ 11차)

- 커버링 인덱스 `sales_day, product_id, sales_count` 추가
```sql
CREATE INDEX idx_sales_day_product_salescount ON p_sales_agg_day (sales_day, product_id, sales_count);
```

- `EXPLAIN` 결과:
```sql
Using where; Using index; Using temporary; Using filesort
```

- ➡️ `GROUP BY` 및 `ORDER BY SUM(...)` 는 여전히 filesort 유발
- **정렬 연산 자체를 인덱스로 해결 불가**

---

###  구조적 개선: 캐시 테이블 도입 (13차)

- 최근 3일간 누적 판매량을 기준으로 랭킹을 미리 집계
- 테이블 구조:
```sql
CREATE TABLE popular_products_daily (
    sales_day DATE NOT NULL,
    product_id BIGINT NOT NULL,
    total_sales BIGINT NOT NULL,
    rank INT NOT NULL,
    PRIMARY KEY (sales_day, rank)
);
```

- 집계 방식:
```sql
SELECT product_id, SUM(sales_count)
FROM p_sales_agg_day
WHERE sales_day BETWEEN CURDATE() - INTERVAL 2 DAY AND CURDATE()
GROUP BY product_id
ORDER BY SUM(sales_count) DESC
LIMIT 5;
```

- 집계 후 `popular_products_daily` 테이블에 저장

---

###  최종 성능 (13차 결과)
| 지표      | 수치          |
| ------- | ----------- |
| `p(95)` | **41ms** ✅  |
| 실패율     | 0%          |
| 평균 응답   | 16ms        |
| VU      | 500명 테스트 통과 ||

> **캐시 테이블 구조 적용 후, 성능이 수백 배 향상됨**  
> → 정렬 없음, group by 없음, 단순 index lookup 만으로 조회 완료


---

## 6-1.  쿼리 성능 분석

### 대상 쿼리

```sql
SELECT
  product_id,
  SUM(sales_count) AS totalSales
FROM
  p_sales_agg_day
WHERE
  sales_day BETWEEN '2025-04-15' AND '2025-04-18'
GROUP BY
  product_id
ORDER BY
  totalSales DESC
LIMIT 5;
```

---

###  슬로우 쿼리 로그 (9차 테스트 기준)

```text
# Query_time: 0.589460  Lock_time: 0.000012 Rows_sent: 5  Rows_examined: 300002
```

- **쿼리 실행 시간: 0.58초**
- 조회 row: **30만 건** (3일 × 10만건)
- 결과 row: **5건**

➡️ 데이터 양 대비 실행 시간이 꽤 걸림. 이유는 쿼리 플랜에서 확인 가능

---

###  EXPLAIN ANALYZE 결과 요약

```sql
> Limit: 5 row(s)
  → Sort: totalSales DESC
    → Group aggregate: sum(p_sales_agg_day.sales_count)
      → Filter: sales_day BETWEEN ...
        → Index scan on p_sales_agg_day using PRIMARY
```

- `product_id`가 약 **99999개**여서 `GROUP BY` 결과도 99999건
- 거기서 **정렬(ORDER BY totalSales DESC) 후 LIMIT 5**
- 결국 전체 그룹에 대해 정렬이 필요 → 정렬 비용 ↑

#### 병목 원인  – `GROUP BY` 후 전체 정렬

- 10만 그룹 중 5개만 필요해도 **전체 정렬**이 필요
- → 정렬 연산은 메모리 초과 시 디스크 I/O로 이어져 **filesort 발생**

---

###  EXPLAIN (기본 플랜)

| id | select_type | table            | type  | key     | key_len | rows    | filtered | Extra                                          |
|----|-------------|------------------|-------|---------|---------|---------|----------|------------------------------------------------|
| 1  | SIMPLE      | p_sales_agg_day  | index | PRIMARY | 11      | 296583  | 11.11    | Using where; Using temporary; Using filesort  |

#### 주요 키워드 설명
- `Using where` → 조건절 필터 적용 OK
- ❗ `Using temporary` → GROUP BY로 인한 임시 테이블 생성
- ❗ `Using filesort` → 정렬 연산 추가 발생

➡️ 이 두 가지가 **MySQL 성능 이슈의 주요 원인**

---

###  커버링 인덱스 적용 (11차)

```sql
CREATE INDEX idx_sales_day_product_salescount
  ON p_sales_agg_day(sales_day, product_id, sales_count);
```

#### 적용 후 EXPLAIN 결과

| type  | key                             | Extra                                          |
|-------|----------------------------------|------------------------------------------------|
| range | idx_sales_day_product_salescount | Using where; Using index; Using temporary; Using filesort |

- 인덱스는 적용되었으나
- 여전히 `Using temporary`, `Using filesort` 존재
- → `SUM(sales_count)`은 **인덱스 기반 정렬 불가**, B-Tree 구조와 안 맞음

---

### 커버링 인덱스 적용 후 성능
| 지표    | 결과                 |
| ----- | ------------------ |
| 평균 응답 | 9.9초               |
| 실패율   | 11.5%              |
| p(95) | 19.2초              |
| 결론    | ✅ 인덱스는 적용됐으나 효과 미미 |미

---

### 최종 진단 요약
| 원인         | 설명                             |
| ---------- | ------------------------------ |
| `GROUP BY` | 결과 row 수가 많음 (~10만 건)          |
| `ORDER BY` | 집계된 total_sales 정렬은 인덱스로 커버 불가 |
| `LIMIT`    | 정렬 후 자르기지만 정렬 비용은 그대로 발생       |
| 임시 테이블     | 메모리 부족 시 디스크로 쓰며 성능 저하 발생      |
| filesort   | 정렬 → 메모리 정렬 실패 시 디스크 접근으로 연결됨  ||

➡️ **쿼리 튜닝만으로는 한계에 도달**  
→ 구조적인 개선 필요

---

## ✅ 구조 개선 후 효과 요약 (13차 이후)

| 항목 | 개선 전 | 개선 후 (캐싱 구조 적용) |
|------|----------|----------------------------|
| 쿼리 | GROUP + ORDER + LIMIT | 단순 SELECT + PK 조회 |
| 정렬 비용 | 높음 (filesort) | 없음 |
| 응답시간 p(95) | 15~19초 | **41ms** ✅ |
| 실패율 | 8~11% | 0% |
| DB 부하 | 높음 (CPU & IO) | 매우 낮음 |


## 🔢 성능 테스트 결과 비교표

|테스트 차수|변경 사항|평균 응답(ms)|p90 응답(ms)|p95 응답(ms)|실패율 (%)|주요 병목 원인|
|---|---|---|---|---|---|---|
|1차|최초 쿼리 (GROUP + ORDER + LIMIT)|7677|14675|14974|83.5|`filesort`, `temporary table`, 커넥션 풀 부족|
|2차|HikariCP 커넥션 풀 10 → 20|5725|11113|11528|0.2|정렬 병목 여전|
|3차|커넥션 풀 20 → 16|5725|11113|11528|0.2|동일|
|4차|커버링 인덱스 추가|9921|18968|19212|11.5|정렬 병목 유지 (`filesort` 발생)|
|✅ 13차 (최종)|집계 테이블 + 정렬 제거|**16**|**23**|**41**|**0.0**|❌ 없음 (정렬/집계 제거됨)|

---

### 요약
- 단순 인덱스 튜닝만으로는 **정렬 병목 해결 불가**
- **집계 테이블 도입 후 성능 400~600배 개선**
- 정렬, GROUP BY, LIMIT 제거로 쿼리 속도 폭발적으로 개선됨
- 실패율 0%, 평균 응답 16ms → 완벽한 응답성 확보

---


## 7. 목표 수치

| 항목 | 목표 | 달성 여부 |
|------|------|------------|
| `http_req_duration` p(95) | < 300ms | ✅ 41ms |
| 실패율 | < 5% | ✅ 0% |
| 커넥션 고갈 | 없음 | ✅ 없음 |
| TPS | 100+ | ✅ 106 req/s 이상 |

---

## 8. 기대 효과
- 인기 상품 조회 API를 **고성능 API로 안정화**
- 트래픽 급증에도 **성능 저하 없이 대응 가능**
- 서버 부하 감소 → 커넥션, CPU, IO 여유 확보
- 향후 "기간 선택", "카테고리 인기 상품" 등 **확장성 보장된 구조**

---

## 9. 결론
- 인기 상품 조회와 같은 **정렬 기반 상위 N 쿼리**는,  
  **집계 + 정렬 + LIMIT** 조합일 경우 인덱스 튜닝만으로는 해결 불가
- MySQL의 구조적 한계를 회피하고,
- **정적 결과 테이블로 분리하여 캐싱**한 방식이  
  **궁극적인 병목 해소 방법**이었음
---


## 추가 최적화 고려 항목
- `tmp_table_size`, `max_heap_table_size` 조정
- MySQL `InnoDB` 튜닝 (buffer pool, join buffer size 등)
- 배치 자동화 → `Spring Scheduler`, `cron`, `Spring Batch`
- 결과를 Redis 등으로 추가 캐싱하면 극한 속도 가능

